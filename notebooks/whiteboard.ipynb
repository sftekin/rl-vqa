{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1591, 9)\n",
      "(1591, 9)\n",
      "(1592, 9)\n",
      "(1592, 9)\n",
      "(1592, 9)\n",
      "(1592, 9)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "infer_dir = \"../results/inference\"\n",
    "\n",
    "# task_name = \"okvqa\"\n",
    "# ds_split = \"train\"\n",
    "\n",
    "# task_name = \"mmmu\"\n",
    "# ds_split = \"validation\"\n",
    "\n",
    "task_name = \"mmmu_pro\"\n",
    "ds_split = \"test\"\n",
    "\n",
    "\n",
    "model_names = [\"llava-v1.6-vicuna-7b-hf\", \"llava-v1.6-vicuna-13b-hf\",\n",
    "               \"Qwen2.5-VL-7B-Instruct\", \"InternVL2-8B\",\n",
    "               \"deepseek-vl2-tiny\", \"deepseek-vl2-small\"]\n",
    "\n",
    "\n",
    "def extract_letter(text):\n",
    "    match = re.search(r\"\\((\\w)\\)\", text)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "error_list = []\n",
    "for mn in model_names:\n",
    "    data_path = os.path.join(infer_dir, task_name, ds_split, f\"{mn}_output.csv\")\n",
    "    data_df = pd.read_csv(data_path)\n",
    "\n",
    "    arr_path = os.path.join(infer_dir, task_name, ds_split, f\"{mn}_prob.npy\")\n",
    "    prob_arr = np.load(arr_path)\n",
    "\n",
    "    start_chr = 'A'\n",
    "    choices = []\n",
    "    for i in range(prob_arr.shape[1]):\n",
    "        choices.append(start_chr)\n",
    "        start_chr = chr(ord(start_chr) + 1)\n",
    "\n",
    "    prob_pred = []\n",
    "    for i in np.argmax(prob_arr, axis=1):\n",
    "        prob_pred.append(choices[i])\n",
    "    prob_pred = np.array(prob_pred, dtype=str)\n",
    "\n",
    "    generated_outputs = data_df[\"generated_outputs\"].values\n",
    "\n",
    "    extracted_outputs = []\n",
    "    for output in generated_outputs:\n",
    "        pred_txt = str(output)[:10].strip()\n",
    "        if \"\\n\" in pred_txt:\n",
    "            pred_txt = pred_txt.split(\"\\n\")[1]\n",
    "        if \"(\" in pred_txt or \")\" in pred_txt:\n",
    "            pred_txt = extract_letter(pred_txt)\n",
    "        extracted_outputs.append(pred_txt[:1].upper())\n",
    "    extracted_outputs = np.array(extracted_outputs)\n",
    "\n",
    "    labels = data_df[\"answer\"].values.astype(str) \n",
    "    if task_name == \"mmmu_pro\" and \"llava\" not in mn:\n",
    "        extracted_outputs = np.delete(extracted_outputs, (1017), axis=0)\n",
    "        prob_pred = np.delete(prob_pred, (1017), axis=0)\n",
    "        labels = np.delete(labels, (1017), axis=0)\n",
    "\n",
    "    errors = labels == extracted_outputs.astype(str)\n",
    "    error_list.append(errors.astype(int))\n",
    "    acc = np.mean(errors)\n",
    "\n",
    "    print(prob_arr.shape)\n",
    "    # print(mn, acc, np.mean(data_df[\"answer\"].values.astype(str) == prob_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "exp_dict = torch.load(\"../results/ensemble/exp_result.pth\")\n",
    "error_arr = np.array(error_list)\n",
    "\n",
    "logits = exp_dict[\"logits\"]\n",
    "ens_preds = logits[:, -9:].argmax(axis=1)\n",
    "ens_err = (ens_preds == exp_dict[\"labels\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_path = \"../results/inference/ocr/train\"\n",
    "\n",
    "model_names = [\"Qwen2.5-VL-7B-Instruct\", \"llava-v1.6-vicuna-7b-hf\", \"llava-v1.6-vicuna-13b-hf\"]\n",
    "\n",
    "model_outputs = []\n",
    "answers = []\n",
    "questions = []\n",
    "for mn in model_names:\n",
    "    data_df = pd.read_csv(f\"{data_path}/{mn}_output.csv\", index_col=0)\n",
    "    model_outputs.append(data_df[\"generated_outputs\"].values)\n",
    "    answers = data_df[\"answer\"].values\n",
    "    questions = data_df[\"question\"].values\n",
    "model_outputs = np.array(model_outputs).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3001, 3), (3001,), (3001,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.shape, answers.shape, questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, tokenized_inputs, labels, global_attention_tokens=None, negative_inputs=None):\n",
    "        self.tokenized_inputs = tokenized_inputs\n",
    "        self.labels = labels\n",
    "        self.global_attention_tokens = global_attention_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # input_ids = self.tokenized_inputs['input_ids'][idx]\n",
    "        # attention_mask = self.tokenized_inputs['attention_mask'][idx]\n",
    "        input_ids = torch.tensor(self.tokenized_inputs[idx].ids)\n",
    "        attention_mask = torch.tensor(self.tokenized_inputs[idx].attention_mask)\n",
    "        global_attentions = []\n",
    "        start = False\n",
    "        for i in input_ids:\n",
    "            if start:\n",
    "                if i == 50266:\n",
    "                    start = False\n",
    "                global_attentions.append(1)\n",
    "            else:\n",
    "                if i == 50265:\n",
    "                    start = True\n",
    "                global_attentions.append(0)\n",
    "        global_attentions = torch.tensor(global_attentions)        # token_type_ids = self.tokenized_inputs['token_type_ids'][idx]\n",
    "        label = self.labels[idx]\n",
    "        return_dict = {'input_ids': input_ids,\n",
    "                       \"labels\": label,\n",
    "                       'attention_mask': attention_mask,\n",
    "                       'global_attention_mask': global_attentions}\n",
    "\n",
    "        return return_dict\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
